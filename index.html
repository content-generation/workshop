<!DOCTYPE html>
<html>
<head>
	<title>Ecom-Gen Kdd 2022</title>  
	<link rel="stylesheet" type="text/css" href="css/styles.css">
<style type="text/css">


	.topnav {
  background-color: #FEFEFE;
  color: #04143A;
  overflow: hidden;
}

/* Style the links inside the navigation bar */
.topnav a {
  float: right;
  color: #04143A;
  text-align: right;
  padding: 34px 36px 34px 34px;
  text-decoration: none;
  font-size: 17px;

}

/* Change the color of links on hover */
.topnav a:hover {
  background-color: #4A90E2;
  color: black;
}

/* Add a color to the active/current link */
.topnav a.active {
  background-color: #4A90E2;
  color: white;
}
</style>
</head>

<body>
 <div class="topnav">
 	<a href="#organizers">Organizers</a>
  	<a href="#pc">Program Committee</a>
  	<a href="#program">Program</a>
  	<a href="#dates">Important Dates</a>
	<a href="#cfp">CFP</a>

</div> 



	<div class="container">
		<div class="hero">
			<h1 class="name">First Content Understanding and Generation for E-commerce Workshop</h1>
			<span class="job-title"><a target='_blank' href='https://kdd.org/kdd2022/'>KDD 2022</a></span>

			
		</div>
	</div>

<!-- Skills and intrest section -->
	<div class="container">
		<div class="sections" id='cfp'>
			<h2 class="section-title" >Call for Papers</h2>

		     <p>Online experience on any e-commerce website is largely driven by the content customers interact with. The large volume of diverse content on e-commerce platforms, and the advances in machine learning provide opportunity for gathering insights from e-commerce content and build systems that can reliably generate content to improve shopper experience. The first workshop on content understanding and generation for the e-commerce aims to bring together researchers from industry and academia to discuss recent advances and challenges specific to these areas. </p>
             <p>The workshop is a half-day event. We encourage submission of novel work-in-progress papers that show promising directions or demonstration systems, to facilitate discussion during the workshop. The workshop will solicit contributions related to the theme of supporting generation and curation of content for e-commerce which includes (but is not limited to):</p>
             <table><tr>
             	<td style="width:45%;">
                    <ul>
                        <li>Cold start brand/product summary or promotional video generation </li>
                        <li>Domain adaptation methods for understanding user submitted product review texts and images</li>
                        <li>Domain adaptation methods for recognition of products in non-natural datasets</li>
                        <li>Novel approaches to generate and evaluate product catalogue, review and comparison summaries</li>
                        <li>Multimodal techniques for matching image and text from product feature/advertisement videos and product description</li>
                        <li>Multimodal and multi-view content modelling aggregating information from multiple product data sources (including text, images, and video) to support product description or advertisement creation</li>
						<li>Multimodal techniques for understanding affective expressions, including non-visual signals such as audio or speech from product videos and advertisements</li>
                        
                        
                    </ul>
             	</td>
             	<td style="width:50%;">
                    <ul>
                        <li>Multimodal action/scene recognition in product feature/advertisement videos across product verticals like sports, healthcare, entertainment or lifestyle</li>
                        <li>Different approaches and metrics to assess the visual appeal of e-commerce content</li>
                        <li>Product catalogue moderation and optimization</li>
                        <li>Guided generative models for images, audio and videos based on product script and brand story</li>
                        <li>Product description or brand store layout/template generation guided by business metrics such as click through rate (CTR) or revenue</li>
                        <li>Generation of interpretable and actionable insights from product catalogue and user submitted reviews for content creators</li>
                        <li>Few shot learning approaches to bootstrap generation models for new brands, products or demographics</li>
                        <li>Evaluation metrics to assess the quality of generated content</li>
                        <li>Cold start modelling for new category or product</li>
                    </ul>   
             	</td>   
             </tr>
         </table>
             <div>
                 <p>
                    We solicit two types of submissions – full papers of 6 pages and short papers of at most 2 pages excluding references. The submissions should be anonymized for double blind reviews. Please omit author names or affiliations to maintain anonymity. The submissions must be in PDF format and use two-columns ACM Conference Proceeding template. Template guidelines are <a href='https://www.acm.org/publications/proceedings-template' target='_blank'>here</a>. Submit your paper through the  workshop CMT submission site: <a href='https://cmt3.research.microsoft.com/EcomGen2022' target='_blank'>https://cmt3.research.microsoft.com/EcomGen2022</a>. The accepted papers will be published on the workshop website. 
</p>
             </div> 
		</div>
	</div>

	<div class="container">
		<div class="sections" id='dates'>
			<h2 class="section-title" >Important Dates</h2>
			Following are the proposed important dates for the workshop. All deadlines are due 11:59pm anywhere on earth.
                        <ul>
                            <li> Paper submission deadline: <strike>May 26th, 2022</strike> June 9th, 2022 </li>
                            <li> Paper review begins: <strike>May 28th, 2022 </strike> June 11th, 2022 </li>
                            <li> Notification of decision: July 6th, 2022  </li>
                            <li> Camera-ready due: <strike>July 4th, 2022</strike> July 21st 2022</li>
                        </ul>
		</div>
	</div>	

	
<div class="container">
		<div class="sections"  id='program'>
			<h2 class="section-title">Program</h2>
      The following papers have been accepted as a talk/poster at the workshop. 
      <br/><br/>
      <div class="paper-card">
          <div class="papers" >
            <h3>Machine Learning Attribution: Inferring item-level impact from slate recommendation in e-commerce</h3>
            <span>Shenghe Xu (Amazon)*; Yan Zhao (Amazon); Sameer Kanase (Amazon); Mitchell Goodman (Amazon); Saad Khan (Amazon); Brent Payne (Amazon); Patricia Grao (Amazon)</span>
            <br/><br/>
            <h3>Catalog Phrase Grounding (CPG): Grounding of Product Textual Attributes in Product Images for e-commerce Vision-Language Applications</h3>
            <span>Wenyi Wu (Amazon)*; Karim Bouyarmane (Amazon); Ismail Tutar (Amazon)</span>
            <br/><br/>
            <h3>StFT: Style loss and Fourier Transformation for Domain Gap Reduction</h3>
            <span>Sarthak Srivastava (Amazon)*; Khaleeque Ansari (Amazon)</span>
            <br/><br/>
            <h3>Semi-supervised Named Entity Recognition to solve label scarcity challenges for E-Commerce use-cases</h3>
            <span>Suman Banerjee (Flipkart)*; Ayesha Siddiqa (Flipkart); Nikesh Garera (Flipkart)</span>
            <br/><br/>
            <h3>Leveraging Co-browse Information for Explainable Product Clustering in the Attribute Space</h3>
            <span>Sneh Gupta (Flipkart, Internet Pvt)*; Naman Kabra (Flipkart); Suryanaman Chaube (Flipkart); Mayank Kant (Flipkart)</span>
            <br/><br/>
            <h3>Answer Generation for Questions With Multiple Information Sources in E-Commerce</h3>
            <span> Anand A R (Flipkart)* </span>
            <br/><br/>
            <h3>MMT4: Multi Modality To Text Transfer Transformer</h3>
            <span>Amir Tavanaei (Amazon)*; Karim Bouyarmane (Amazon); Iman Keivanloo (Amazon); Ismail Tutar (Amazon)</span>
            <br/><br/>
            <h3>Automated Transformation of Photoshoot Images into Promotional Banners at Scale</h3>
            <span>Shivang Singhal (Flipkart)*; Aditya R Rachakonda (Flipkart); Abhay Gupta (Flipkart); Aditya Sharma (Flipkart)</span>
            <br/><br/>
            <h3>Learning to Diversify for Product Question Generation</h3>
            <span>Haggai Roitman (IBM Research Haifa)*; Uriel Singer (Technion, Israel Institute of Technology); yotam eshel (eBay); Alexander Nus (eBay); Eliyahu Kiperwasser (eBay)</span>
          </div>
      </div>
      <br/><br/>
      <p>Five invited speakers shall talk about various topics associated with E-commerce content generation and moderation. </p> 
			<div class="container cards">
    
        <div class="card" onclick="popupFunction('talkAbstractAleix')">
          <div class="skill-level">
           <img src="assets/img/aleix_headshot.jpg"> 
          </div>

          <div class="skill-meta" >

            <h3>Aleix Martinez</h3>
            <span>Ohio State University</span>
          </div>
        </div>
        <div class="modal-content" id="talkAbstractAleix">
                <span class="close" onclick="closePopup('talkAbstractAleix')">&times;</span>
                <h3>Shopping from images</h3>
                <div >
                The talk covers machine learning and computer vision algorithms to: 1. detect objects in cluttered and un-cluttered scenes, 2. classify these objects within a taxonomy of high-level and fine-gran object categories. and 3. identify objects visual similarity. Despite major advances, these three problems are still challenging. It will also review these difficulties and introduce our proposed solutions. I will the show results on a large scale application with clean as well as highly-cluttered real-world images.
                </div>  
        </div>

         <div class="card" onclick="popupFunction('talkAbstractLydia')">
          <div class="skill-level" >
           <img src="assets/img/chilton-banner-headshot.jpg"> 
          </div>

          <div class="skill-meta" >
            <h3>Lydia Chilton</h3>
            <span>Columbia University</span>
          </div>
        </div>

        <div class="modal-content" id="talkAbstractLydia">
                <span class="close" onclick="closePopup('talkAbstractLydia')">&times;</span>
                <h3>AI Tools for Design and Innovation</h3>
                <div >
                How can computational tools and AI help people be better at innovation and creative problem-solving? When solving a problem, people have the tendency to fixate on one problem or solution. If that one idea doesn’t work, they get stuck. To avoid getting stuck, the design process encourages people to have multiple ideas, and explore the space of possibilities before deciding on a problem or a solution. Although this works, it’s highly complex- requiring people to follow many threads at once. We show how AI and other computational tools can help simplify and speed up the most cognitively taxing aspects of the design process:  1. Collecting multiple partial solutions, 2. Synthesizing partial solution into multiple prototypes, 3. Quickly iterating on prototypes to produce an MVP.
                </div>  
        </div>
          
        <div class="card" onclick="popupFunction('talkAbstractKristen')">
          <div class="skill-level">
           <img src="assets/img/kristen-grauman-headshot.jpg" style="margin:-35px 5px 0px 10px;"> 
          </div>

          <div class="skill-meta ">
            <h3>Kristen Grauman</h3>
            <span>University of Texas at Austin</span>
          </div>
        </div>
        <div class="modal-content" id="talkAbstractKristen">
                <span class="close" onclick="closePopup('talkAbstractKristen')">&times;</span>
                <h3>Style and Influence From In-the-Wild Fashion Photos</h3>
                <div > 
                The fashion domain is a magnet for computer vision. New vision problems are emerging in step with the fashion industry's rapid evolution towards an online, social, and personalized business. Style models, trend forecasting, and recommendation all require visual understanding with rich detail and subtlety. I will present our work developing computer vision methods for fashion. To begin, we explore how to discover styles from Web photos, so as to optimize mix-and-match wardrobes, suggest minimal edits to make an outfit more fashionable, or recommend clothing that flatters diverse human body shapes.  Next, turning to the world stage, we investigate fashion forecasting and influence.  Learned directly from photos, our models discover the “underground map” of a city based on the different clothes people wear, and they forecast what styles will be popular in the future by capturing how trends propagate across 44 major world cities.  Finally, building on this notion of fashion influence, we quantify which cultural factors (as captured by millions of news articles) most affect the clothes people choose to wear across a century of fashion photos.
                </div>  
        </div>

        <div class="card" onclick="popupFunction('talkAbstractSam')">
          <div class="skill-level">
           <img src="assets/img/swiseman_profile.png"> 
          </div>

          <div class="skill-meta">
            <h3>Sam Wiseman</h3>
            <span>Duke University</span>
          </div>
        </div>
        <div class="modal-content" id="talkAbstractSam">
                <span class="close" onclick="closePopup('talkAbstractSam')">&times;</span>
                <h3>Data-to-text Generation from Retrieved Nearest Neighbors</h3>
                <div > 
                I’ll describe some recent work which attempts to generate text by directly cutting and pasting together pieces of text that have been retrieved from nearest neighbors, focusing in particular on a table-to-text generation scenario. The goal of this approach is to make text generation systems both more interpretable and easier to debug: problematic generations can be easily traced to the retrieved neighbors out of which they were created. I will also describe some ongoing work, which seeks to speed up the training of these cut-and-paste generation models.
                </div>  
        </div>

        <div class="card">
          <div class="skill-level">
           <img src="assets/img/jacopo.jpg"> 
          </div>

          <div class="skill-meta">
            <h3>Jacopo Tagliabue</h3>
            <span>Coveo</span>
          </div>
        </div>

		  </div>
	</div>
	
<div class="container">
		<div class="sections" id='pc'>
			<h2 class="section-title" >Program Committee</h2>
					<span class="point"></span>

			 <ul>
                            <li> Stephen Guo, Walmart Labs </li>
                            <li> Musen Wen, Walmart Labs </li>
                            <li> Djordje Gligorijevic, Ebay </li>
                            <li> Yuri Brovman, Ebay Ads</li>
                            <li> Menghan Wang, Ebay Ads</li>
                            <li> Wei Zhou, Ebay Ads </li>
                            <li> Deepalakshmi Gopinath, Ebay </li>
                            <li> Yichao Zhou, Google</li>
                            <li> Aayush Prakash, Facebook </li>
                            <li> Procheta Sen, UCL </li>
                            <li> Ganesh Jawahar, UBC </li>
                            <li> Kevin Yen, Yahoo! Research</li>
                            <li> Keqian Li, Yahoo! Research </li>
                            <li> Shaunak Mishra, Amazon Ads  </li>
                            <li> Soumya Roy, Amazon Ads</li>
                            <li> Shilpa Ananth, Amazon Ads</li>
                            <li> Yashal Kanungo, Amazon Ads  </li>
                            <li> Indraneil Paul, Amazon Ads  </li>
                            <li> Bryan Wang, Amazon Machine Learning  </li>
                            <li> Yang Liu, Amazon Machine Learning  </li>
                            <li> Jinmiao Fu, Amazon Machine Learning  </li>
                            <li> Sameer Kanase, Amazon  </li>
                </ul>
		</div>

	</div>

<div class="container">
		<div class="sections" id='organizers'>
			<h2 class="section-title" >Organizers</h2>
			 <ul>
                        <li> Sumit Negi, Amazon Ads </li>
                            <li> Rajdeep Banerjee, Amazon Ads</li>
                            <li> Manisha Verma, Amazon Ads </li>
                            <li> Pooja A, Amazon Ads </li>
                            <li> Lydia Chilton, Columbia University </li>
                            <li> Mithun Das Gupta, Microsoft</li>
                            <li> Vinay P. Namboodiri, University of Bath  </li>
                            <li> Dinesh Garg, IBM Research </li>
                </ul>
		</div>
	</div>
  
  <script type="text/javascript">
    
      // When the user clicks on div, open the popup
      function popupFunction(id) {
        var popup = document.getElementById(id);
        if (popup.style.display  == "none" || popup.style.display  == "") {
          popup.style.display = "block";
        }
        else
        {
          popup.style.display = "none";

        }
      }

      function closePopup(id) {
        var popup = document.getElementById(id);
        popup.style.display = "none";
      }

      
  </script>

</body>
</html>
